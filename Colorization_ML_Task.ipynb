{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# For conversion\n",
    "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_image\n",
    "from torchvision import datasets, transforms    \n",
    "# For utilities\n",
    "import os, shutil, time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, color\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.filters import sobel\n",
    "\n",
    "class RGBtoGrayDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = self.file_list[idx]\n",
    "        img = io.imread(target)\n",
    "        img_original = np.asarray(img)\n",
    "        img_original = resize(img_original, (224, 224), anti_aliasing=True)\n",
    "        img_lab = rgb2lab(img_original)\n",
    "        img_lab = (img_lab + 128) / 255\n",
    "        img_ab = img_lab[:, :, 1:3]\n",
    "        img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
    "        img_original = rgb2gray(img_original)\n",
    "        img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_original = self.transform(img_original)\n",
    "\n",
    "        return img_original, img_ab, img\n",
    "\n",
    "\n",
    "# Define the augmentation transformations\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "])\n",
    "\n",
    "# Pfade zu den Bildern\n",
    "image_dir = 'dataset/student_dataset/train/images'\n",
    "image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir)]\n",
    "\n",
    "\n",
    "# Aufteilung in Trainings- und Validierungsbilder\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply augmentation only to the training dataset\n",
    "train_dataset = RGBtoGrayDataset(train_files)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Erstellen des Validierungsdatasets und Dataloaders\n",
    "val_dataset = RGBtoGrayDataset(val_files)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jpg_files(folder_path):\n",
    "    jpg_count = 0\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            jpg_count += 1\n",
    "\n",
    "    return jpg_count\n",
    "\n",
    "# Ordnerpfad zum Dataset\n",
    "dataset_folder = 'dataset/student_dataset/train/images'\n",
    "\n",
    "# Anzahl der JPG-Dateien im Dataset-Ordner\n",
    "jpg_file_count = count_jpg_files(dataset_folder)\n",
    "print(f\"Anzahl der JPG-Dateien: {jpg_file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_size(dataset):\n",
    "    print(f\"Dataset Size: {len(dataset)}\")\n",
    "\n",
    "# Ausgabe der Größe des Trainingsdatensatzes\n",
    "print_dataset_size(train_dataset)\n",
    "\n",
    "# Ausgabe der Größe des Validierungsdatensatzes\n",
    "print_dataset_size(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of images to display\n",
    "num_images = 10\n",
    "\n",
    "# Get a batch of images from the train loader\n",
    "images, _, original_images = next(iter(train_loader))\n",
    "\n",
    "# Set the figure size\n",
    "fig, axes = plt.subplots(num_images, 2, figsize=(8, 20))\n",
    "\n",
    "# Display the images\n",
    "for i in range(num_images):\n",
    "    # Display augmented image\n",
    "    augmented_image = images[i].permute(1, 2, 0)  # Reorder dimensions for display (C, H, W) -> (H, W, C)\n",
    "    axes[i, 0].imshow(augmented_image, cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Display original image\n",
    "    original_image = original_images[i]\n",
    "    axes[i, 1].imshow(original_image)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Display size of each image\n",
    "    augmented_size = augmented_image.shape[:2]\n",
    "    original_size = original_image.shape[:2]\n",
    "    axes[i, 0].text(5, 5, str(augmented_size), color='black', fontsize=10, verticalalignment='top')\n",
    "    axes[i, 1].text(5, 5, str(original_size), color='black', fontsize=10, verticalalignment='top')\n",
    "\n",
    "# Set titles\n",
    "axes[0, 0].set_title('Augmented Images')\n",
    "axes[0, 1].set_title('Original Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import cat\n",
    "\n",
    "class ColorizationNet(nn.Module):\n",
    "  def __init__(self, input_size=128):\n",
    "    super(ColorizationNet, self).__init__()\n",
    "    MIDLEVEL_FEATURE_SIZE = 128\n",
    "\n",
    "    ## First half: ResNet\n",
    "    resnet = models.resnet18(num_classes=365) \n",
    "    # Change first conv layer to accept single-channel (grayscale) input\n",
    "    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1)) \n",
    "    # Extract midlevel features from ResNet-gray\n",
    "    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])\n",
    "\n",
    "    ## Second half: Upsampling\n",
    "    self.upsample = nn.Sequential(     \n",
    "      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n",
    "      nn.Upsample(scale_factor=2)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "\n",
    "    # Pass input through ResNet-gray to extract features\n",
    "    midlevel_features = self.midlevel_resnet(input)\n",
    "\n",
    "    # Upsample to get colors\n",
    "    output = self.upsample(midlevel_features)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import *\n",
    "\n",
    "model = ColorizationNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=20, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "  '''Show/save rgb image from grayscale and ab channels\n",
    "     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "  plt.clf() # clear matplotlib \n",
    "  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n",
    "  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n",
    "  color_image = lab2rgb(color_image.astype(np.float64))\n",
    "  grayscale_input = grayscale_input.squeeze().numpy()\n",
    "  if save_path is not None and save_name is not None: \n",
    "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))\n",
    "  \n",
    "  return color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "  print('Starting training epoch {}'.format(epoch))\n",
    "  model.train()\n",
    "  \n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (input_gray, input_ab, target) in enumerate(train_loader):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
    "\n",
    "    # Record time to load data (above)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Run forward pass\n",
    "    output_ab = model(input_gray) \n",
    "    loss = criterion(output_ab, input_ab) \n",
    "    losses.update(loss.item(), input_gray.size(0))\n",
    "\n",
    "    # Compute gradient and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    # Record time to do forward and backward passes\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
    "    if i % 25 == 0:\n",
    "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.6f} ({loss.avg:.6f})\\t'.format(\n",
    "              epoch, i, len(train_loader), batch_time=batch_time,\n",
    "             data_time=data_time, loss=losses)) \n",
    "\n",
    "  print('Finished training epoch {}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, save_images, epoch):\n",
    "  model.eval()\n",
    "\n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  already_saved_images = False\n",
    "  for i, (input_gray, input_ab, target) in enumerate(val_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Use GPU\n",
    "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
    "\n",
    "    # Run model and record loss\n",
    "    output_ab = model(input_gray) # throw away class predictions\n",
    "    loss = criterion(output_ab, input_ab)\n",
    "    losses.update(loss.item(), input_gray.size(0))\n",
    "\n",
    "    # Save images to file\n",
    "    if save_images and not already_saved_images:\n",
    "      already_saved_images = True\n",
    "      for j in range(min(len(output_ab), 10)): # save at most 5 images\n",
    "        save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}\n",
    "        save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)\n",
    "        to_rgb(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
    "\n",
    "    # Record time to do forward passes and save images\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to both value and validation\n",
    "    if i % 25 == 0:\n",
    "      print('Validate: [{0}/{1}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.6f} ({loss.avg:.6f})\\t'.format(\n",
    "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "  print('Finished validation.')\n",
    "  return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "  criterion = criterion.cuda()\n",
    "  model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folders and set parameters\n",
    "os.makedirs('outputs/color', exist_ok=True)\n",
    "os.makedirs('outputs/gray', exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "save_images = True\n",
    "best_losses = 1e10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_losses = float('inf')\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "counter = 0  # Counter to track the number of epochs without improvement\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train for one epoch, then validate\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        losses = validate(val_loader, model, criterion, save_images, epoch)\n",
    "    \n",
    "    # Save checkpoint and replace old best model if current model is better\n",
    "    if losses < best_losses:\n",
    "        best_losses = losses\n",
    "        torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.6f}.pth'.format(epoch+1, losses))\n",
    "        counter = 0  # Reset the counter since there was improvement\n",
    "    else:\n",
    "        counter += 1  # Increment the counter if there was no improvement\n",
    "        \n",
    "        # Check if early stopping criterion is met\n",
    "        if counter >= patience:\n",
    "            print(\"Validation loss did not improve for {} epochs. Stopping training.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss 0.360458 Batchsize 32 resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def to_rgb_new(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "    plt.clf()  # Clear matplotlib\n",
    "    color_image = torch.cat((grayscale_input, ab_input), 0).numpy()  # Combine channels\n",
    "    color_image = color_image.transpose((1, 2, 0))  # Rescale for matplotlib\n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    color_image = lab2rgb(color_image.astype(np.float64))\n",
    "    grayscale_input = grayscale_input.squeeze().numpy()\n",
    "    if save_path is not None and save_name is not None:\n",
    "        plt.imsave(fname=os.path.join(save_path, save_name), arr=color_image)\n",
    "\n",
    "    return color_image\n",
    "\n",
    "\n",
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "\n",
    "    # Create folder to save predicted images\n",
    "    save_path = \"test_pred\"\n",
    "    if not os.path.exists(\"test_pred\"):\n",
    "        os.makedirs(\"test_pred\")\n",
    "\n",
    "    for i, (input_gray, _) in enumerate(test_loader):\n",
    "        # Use GPU\n",
    "        if use_gpu:\n",
    "            input_gray = input_gray.cuda()\n",
    "\n",
    "        # Run model\n",
    "        output_ab = model(input_gray)  # throw away class predictions\n",
    "        \n",
    "        for j in range(len(output_ab)):\n",
    "            save_name = 'img-{}.jpg'.format(i * test_loader.batch_size + j)\n",
    "            save_path_img = save_path\n",
    "            to_rgb_new(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path_img, save_name=save_name)\n",
    "\n",
    "    print('Finished testing.')\n",
    "\n",
    "# Define the path to the test dataset\n",
    "test_data_path = \"dataset/student_dataset/test_color\"\n",
    "\n",
    "# Define the transformation to be applied to the test images\n",
    "# Define the transformation to be applied to the test images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert the image to grayscale (1 channel)\n",
    "    transforms.ToTensor()  # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "# Create the test loader\n",
    "batch_size = 64  # Specify the batch size for the test loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model = ColorizationNet()\n",
    "model.load_state_dict(torch.load('checkpoints/model-epoch-7-losses-0.000205.pth'))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "test(test_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the folder containing the JPEG files\n",
    "folder_path = \"test_pred\"\n",
    "\n",
    "# Initialize an empty array to store the images\n",
    "image_array = np.zeros((50, 224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "files = sorted(files, key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "print(files)\n",
    "# Iterate over each file in the folder\n",
    "for i, file_name in enumerate(files):\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Read the image using PIL\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_array[i] = np.array(image)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Turn off the axis labels\n",
    "    plt.show()\n",
    "        \n",
    "# Save the array as a NumPy file\n",
    "np.save(\"image_array.npy\", image_array)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(\"Array shape:\", image_array.shape)\n",
    "print(\"Array saved as 'image_array.npy'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image array from the saved NumPy file\n",
    "image_array = np.load(\"image_array.npy\")\n",
    "\n",
    "# Iterate over each image in the array\n",
    "for i in range(image_array.shape[0]):\n",
    "    # Get the image\n",
    "    image = image_array[i]\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import itertools\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "weight_decays = [0.0, 0.0001, 0.001]\n",
    "\n",
    "\n",
    "# Create a grid of all possible hyperparameter combinations\n",
    "hyperparameter_grid = list(itertools.product(learning_rates, weight_decays))\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Loop over each hyperparameter combination in the grid\n",
    "for hyperparameters in hyperparameter_grid:\n",
    "    learning_rate, weight_decay = hyperparameters\n",
    "\n",
    "    # Create a new model instance\n",
    "    model = ColorizationNet()\n",
    "    if use_gpu:\n",
    "        model = model.cuda()  # Move the model to GPU\n",
    "\n",
    "    # Define the loss function, optimizer, and scheduler\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.1, verbose=True)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        train(train_loader, model, criterion, optimizer, epoch)  # Pass use_gpu flag to train function\n",
    "        with torch.no_grad():\n",
    "            losses = validate(val_loader, model, criterion, save_images, epoch)  # Pass use_gpu flag to validate function\n",
    "        scheduler.step(losses)\n",
    "\n",
    "    # Calculate the validation loss\n",
    "    with torch.no_grad():\n",
    "        loss = validate(val_loader, model, criterion, save_images, epoch)  # Pass use_gpu flag to validate function\n",
    "\n",
    "    # Check if this hyperparameter combination is the best so far\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_model = model\n",
    "        best_hyperparameters = hyperparameters\n",
    "\n",
    "# Print the best hyperparameters and loss\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Loss:\", best_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
